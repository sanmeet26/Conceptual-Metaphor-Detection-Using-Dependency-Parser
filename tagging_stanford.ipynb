{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc80f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import *\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f164e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_path = \"C:/Program Files/Java/jdk-18.0.1.1/bin/java.exe\"\n",
    "os.environ[\"JAVAHOME\"] = java_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bca0c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jar = \"C:/Users/Public/utility/stanford-postagger-full-2020-11-17/stanford-postagger.jar\"\n",
    "model = \"C:/Users/Public/utility/stanford-postagger-full-2020-11-17/models/english-bidirectional-distsim.tagger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44d0ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagger = StanfordPOSTagger(model, jar, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a083167",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"face\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a490a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['face']\n"
     ]
    }
   ],
   "source": [
    "words = nltk.word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74484971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('face', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "tagged_words = pos_tagger.tag(words)\n",
    "print(tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8556bae8",
   "metadata": {},
   "source": [
    "### Tagging a locally stored file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3efdc18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96f8bf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              sentences  labels\n",
      "0                     His face became as black as coal.       1\n",
      "1     My uncle is as blind as a bat without his spec...       1\n",
      "2                      Naina was as cool as a cucumber.       1\n",
      "3                   The soldier was as brave as a lion.       1\n",
      "4                             He is cunning like a fox.       1\n",
      "...                                                 ...     ...\n",
      "1810         They like to explore new cities and towns.       0\n",
      "1811       They like to go on hiking and camping trips.       0\n",
      "1812  They like to volunteer at local charities and ...       0\n",
      "1813  They like to watch TV series and binge-watch s...       0\n",
      "1814  They like to spend time with their families an...       0\n",
      "\n",
      "[1815 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pandas.read_csv('C:/Users/sanmeet/Documents/4th_Year/4th_Year_Sem2/BTech_Project/dataset/dataset.csv',encoding=\"ISO-8859-1\",header=[0])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31d125d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0                  1              2            3            4   \\\n",
      "0   (His, PRP$)         (face, NN)  (became, VBD)     (as, RB)  (black, JJ)   \n",
      "1    (My, PRP$)        (uncle, NN)      (is, VBZ)     (as, RB)  (blind, JJ)   \n",
      "2  (Naina, NNP)         (was, VBD)       (as, RB)   (cool, JJ)     (as, IN)   \n",
      "3     (The, DT)      (soldier, NN)     (was, VBD)     (as, RB)  (brave, JJ)   \n",
      "4     (He, PRP)          (is, VBZ)  (cunning, JJ)   (like, IN)      (a, DT)   \n",
      "5     (The, DT)   (expression, NN)       (on, IN)  (her, PRP$)   (face, NN)   \n",
      "6    (My, PRP$)         (wife, NN)      (is, VBZ)     (as, RB)   (busy, JJ)   \n",
      "7     (The, DT)         (hall, NN)      (is, VBZ)     (as, RB)  (clean, JJ)   \n",
      "8    (My, PRP$)      (blanket, NN)      (is, VBZ)     (as, RB)   (soft, JJ)   \n",
      "9    (My, PRP$)  (grandmother, NN)      ('s, POS)   (mind, NN)    (is, VBZ)   \n",
      "\n",
      "           5               6              7              8            9   \\\n",
      "0    (as, IN)      (coal, NN)         (., .)           None         None   \n",
      "1    (as, IN)         (a, DT)      (bat, NN)  (without, IN)  (his, PRP$)   \n",
      "2     (a, DT)  (cucumber, NN)         (., .)           None         None   \n",
      "3    (as, IN)         (a, DT)     (lion, NN)         (., .)         None   \n",
      "4   (fox, NN)          (., .)           None           None         None   \n",
      "5  (was, VBD)        (as, RB)     (cold, JJ)       (as, IN)    (ice, NN)   \n",
      "6    (as, IN)         (a, DT)      (bee, NN)       (in, IN)    (the, DT)   \n",
      "7    (as, IN)         (a, DT)  (whistle, NN)         (., .)         None   \n",
      "8    (as, IN)    (velvet, NN)         (!, .)           None         None   \n",
      "9    (as, RB)     (sharp, JJ)       (as, IN)        (a, DT)  (razor, NN)   \n",
      "\n",
      "                  10      11  \n",
      "0               None    None  \n",
      "1  (spectacles, NNS)  (., .)  \n",
      "2               None    None  \n",
      "3               None    None  \n",
      "4               None    None  \n",
      "5             (., .)    None  \n",
      "6    (mornings, NNS)  (., .)  \n",
      "7               None    None  \n",
      "8               None    None  \n",
      "9             (., .)    None  \n"
     ]
    }
   ],
   "source": [
    "tagged_list2 = []\n",
    "# tagging first 10 sentences in dataset and storing them in a dataframe\n",
    "for i in range(10):\n",
    "#     print(df.loc[i][0])\n",
    "    tokens = nltk.word_tokenize(df.loc[i][0])\n",
    "    tagged_sentence = pos_tagger.tag(tokens)\n",
    "    tagged_list2.append(tagged_sentence)\n",
    "\n",
    "tagged_df2 = pandas.DataFrame(tagged_list2)\n",
    "print(tagged_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c650f1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0              1              2                3   \\\n",
      "0      (His, PRP$)     (face, NN)  (became, VBD)         (as, RB)   \n",
      "1       (My, PRP$)    (uncle, NN)      (is, VBZ)         (as, RB)   \n",
      "2     (Naina, NNP)     (was, VBD)       (as, RB)       (cool, JJ)   \n",
      "3        (The, DT)  (soldier, NN)     (was, VBD)         (as, RB)   \n",
      "4        (He, PRP)      (is, VBZ)  (cunning, JJ)       (like, IN)   \n",
      "...            ...            ...            ...              ...   \n",
      "1810   (They, PRP)    (like, VBP)       (to, TO)    (explore, VB)   \n",
      "1811   (They, PRP)    (like, VBP)       (to, TO)         (go, VB)   \n",
      "1812   (They, PRP)    (like, VBP)       (to, TO)  (volunteer, VB)   \n",
      "1813   (They, PRP)    (like, VBP)       (to, TO)      (watch, VB)   \n",
      "1814   (They, PRP)    (like, VBP)       (to, TO)      (spend, VB)   \n",
      "\n",
      "               4              5                 6                  7   \\\n",
      "0     (black, JJ)       (as, IN)        (coal, NN)             (., .)   \n",
      "1     (blind, JJ)       (as, IN)           (a, DT)          (bat, NN)   \n",
      "2        (as, IN)        (a, DT)    (cucumber, NN)             (., .)   \n",
      "3     (brave, JJ)       (as, IN)           (a, DT)         (lion, NN)   \n",
      "4         (a, DT)      (fox, NN)            (., .)               None   \n",
      "...           ...            ...               ...                ...   \n",
      "1810    (new, JJ)  (cities, NNS)         (and, CC)       (towns, NNS)   \n",
      "1811     (on, IN)   (hiking, NN)         (and, CC)      (camping, NN)   \n",
      "1812     (at, IN)    (local, JJ)  (charities, NNS)          (and, CC)   \n",
      "1813     (TV, NN)   (series, NN)         (and, CC)  (binge-watch, NN)   \n",
      "1814   (time, NN)     (with, IN)     (their, PRP$)    (families, NNS)   \n",
      "\n",
      "                        8            9                  10  \\\n",
      "0                     None         None               None   \n",
      "1            (without, IN)  (his, PRP$)  (spectacles, NNS)   \n",
      "2                     None         None               None   \n",
      "3                   (., .)         None               None   \n",
      "4                     None         None               None   \n",
      "...                    ...          ...                ...   \n",
      "1810                (., .)         None               None   \n",
      "1811          (trips, NNS)       (., .)               None   \n",
      "1812  (organizations, NNS)       (., .)               None   \n",
      "1813          (shows, NNS)       (., .)               None   \n",
      "1814             (and, CC)  (have, VBP)   (meaningful, JJ)   \n",
      "\n",
      "                        11      12    13    14    15    16    17    18  \n",
      "0                     None    None  None  None  None  None  None  None  \n",
      "1                   (., .)    None  None  None  None  None  None  None  \n",
      "2                     None    None  None  None  None  None  None  None  \n",
      "3                     None    None  None  None  None  None  None  None  \n",
      "4                     None    None  None  None  None  None  None  None  \n",
      "...                    ...     ...   ...   ...   ...   ...   ...   ...  \n",
      "1810                  None    None  None  None  None  None  None  None  \n",
      "1811                  None    None  None  None  None  None  None  None  \n",
      "1812                  None    None  None  None  None  None  None  None  \n",
      "1813                  None    None  None  None  None  None  None  None  \n",
      "1814  (conversations, NNS)  (., .)  None  None  None  None  None  None  \n",
      "\n",
      "[1815 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "tagged_list = []\n",
    "# tagging all sentences in dataset and storing them in a dataframe\n",
    "for i in range(df.shape[0]):\n",
    "#     print(df.loc[i][0])\n",
    "    tokens = nltk.word_tokenize(df.loc[i][0])\n",
    "    tagged_sentence = pos_tagger.tag(tokens)\n",
    "    tagged_list.append(tagged_sentence)\n",
    "\n",
    "tagged_df = pandas.DataFrame(tagged_list)\n",
    "print(tagged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5623f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_df.to_csv('tagged_dataset.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
