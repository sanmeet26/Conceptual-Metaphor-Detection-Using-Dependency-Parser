{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "664f1f5a",
   "metadata": {},
   "source": [
    "# Creating an Application for Metaphor Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "740d622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import *\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae8504e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_path = \"C:/Program Files/Java/jdk-18.0.1.1/bin/java.exe\"\n",
    "os.environ[\"JAVAHOME\"] = java_path\n",
    "\n",
    "jar = \"C:/Users/Public/utility/stanford-postagger-full-2020-11-17/stanford-postagger.jar\"\n",
    "model = \"C:/Users/Public/utility/stanford-postagger-full-2020-11-17/models/english-bidirectional-distsim.tagger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "055634ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagger = StanfordPOSTagger(model, jar, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78917817",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The sky is ocean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94afd058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'sky', 'is', 'ocean']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "sentence = sentence.lower()\n",
    "words = nltk.word_tokenize(sentence)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1dbeaecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'DT'), ('sky', 'NN'), ('is', 'VBZ'), ('ocean', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "tagged_words = pos_tagger.tag(words)\n",
    "print(tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b93df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS labels of nouns, pronouns, adjectives and verbs\n",
    "nouns = ['NN', 'NNP', 'NNS', 'NNPS']\n",
    "pronouns = ['PRP', 'PRP$']\n",
    "adjectives = ['JJ', 'JJR', 'JJS']\n",
    "verbs = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a4f50da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d853ee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "495399f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'elsewhere', 'through', 'n’t', 'nobody', 'towards', 'you', 'while', 'many', 'will', 'do', 'seemed', 'herein', 'nevertheless', 'or', 'become', 'and', 'hereupon', 'your', 'namely', 'own', 'make', 'its', 'yet', 'would', 'nor', 'further', 'ca', \"'ve\", 'those', 'call', 'top', 'whom', \"'s\", 'whereafter', 'after', '’s', 'latterly', 'who', 'within', 'has', \"'ll\", 'he', 'hereby', 'seems', 'as', 'his', 'sometimes', 'used', 'may', 'done', 'else', 'an', 'when', 'six', 'part', 'for', 'doing', 'yourselves', 'each', 'upon', 'ten', 'among', 'more', 'fifty', 'their', 'below', 'cannot', 'to', 'thereby', 'up', 'by', 'yours', 'something', 'herself', 'alone', 'several', '’re', 'name', 'all', 'throughout', 'becoming', 'beforehand', '’ll', 'thereafter', 'such', 'have', \"'d\", 'thence', 'often', 'did', 'nothing', 'serious', 'amongst', 'anyone', 'whither', 'therein', 'amount', 'get', 'at', 'four', 'here', 'some', 'had', 'less', 'about', 'back', 'empty', 'why', 'never', 'our', 'himself', 'together', 'eleven', 'anything', 'my', 'a', 'too', 'because', 'around', 'once', 'well', 'few', '’ve', 'one', 'on', 'every', 'before', 'twenty', 'eight', 'onto', 'besides', 'forty', 'front', 'hers', 'whereby', 'under', 'everyone', 'she', 'then', 'out', 'these', 'sometime', 'neither', 'so', 'along', 'been', \"n't\", 'noone', 'where', 'hence', 'again', 'during', 'however', 'whereupon', 'can', 'should', 'either', 'formerly', 'down', 'keep', 'be', 'except', 'nine', 'us', 'without', 'regarding', 'other', 'wherever', 'ours', 'anyway', '’m', 'still', 'not', 'thru', 'full', 'take', 'across', 'already', 'was', 'thus', 'above', 'due', '‘ll', 'sixty', 'quite', 'whole', 'than', 'but', 'the', 'toward', 'n‘t', 'there', 'otherwise', 'per', 'they', 'somehow', 'side', '‘re', 'give', 'whence', 'show', 'very', 'say', 'any', 'almost', 'others', 'everything', 'only', 'via', 'does', 'could', 'of', 'first', 'third', '’d', 'between', \"'m\", 'whenever', 'whoever', 'anyhow', 'perhaps', 'into', 'three', 'them', 'over', 'seem', 'might', 'really', 'with', 'also', 'whatever', 'made', 'same', 'beyond', 'next', 'whether', 'hereafter', 'me', 'various', 'themselves', 'beside', 'mine', 'indeed', 'am', 'whereas', 'much', 'this', 'becomes', 'another', 'i', 'how', 'someone', 'meanwhile', 'although', 'everywhere', 'against', 'if', 'which', 'least', 'are', 'became', 'whose', 'yourself', 'off', \"'re\", 'none', 'mostly', 'enough', 'rather', 'bottom', 'see', 'therefore', 'we', 'her', 'myself', 'must', 'former', 'last', 'moreover', 'that', '‘s', 'always', 'what', 'behind', 'fifteen', 'no', 'being', 'both', 'in', 'unless', 'ever', 'itself', '‘ve', 'twelve', 'go', 're', 'since', 'move', 'two', 'please', 'seeming', 'hundred', 'it', 'just', 'him', 'anywhere', 'somewhere', 'ourselves', 'five', 'thereupon', 'until', 'put', 'wherein', 'nowhere', 'latter', 'even', 'from', 'is', 'were', 'though', 'afterwards', '‘m', 'using', 'now', 'most', '‘d'}\n"
     ]
    }
   ],
   "source": [
    "all_stopwords = nlp.Defaults.stop_words\n",
    "print(all_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aecc1f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get noun chunks\n",
    "def get_noun_phrase(sentence):\n",
    "    nlp_sentence = nlp(sentence)\n",
    "    chunks = list(nlp_sentence.noun_chunks)\n",
    "    return chunks\n",
    "\n",
    "verb = \"\"\n",
    "for i in range(len(tagged_words)):\n",
    "    if tagged_words[i][1] in verbs:\n",
    "        verb = tagged_words[i][0]\n",
    "        break\n",
    "\n",
    "verb_ind = sentence.find(verb)\n",
    "# target_phrase_lst = sentence[:verb_ind].split()\n",
    "# source_phrase_lst = sentence[verb_ind+len(verb)+1:].split()\n",
    "\n",
    "target_noun_phrases_lst = get_noun_phrase(sentence[:verb_ind])\n",
    "source_noun_phrases_lst = get_noun_phrase(sentence[verb_ind+len(verb)+1:])\n",
    "\n",
    "target_noun_phrases_lst=str(target_noun_phrases_lst[0]).split()\n",
    "source_noun_phrases_lst=str(source_noun_phrases_lst[0]).split()\n",
    "\n",
    "# target_noun_phrases_lst = target_noun_phrases.split()\n",
    "# source_noun_phrases_lst = source_noun_phrases.split()\n",
    "\n",
    "target_noun_phrases_lst_without_sw = [word for word in target_noun_phrases_lst if not word in all_stopwords]\n",
    "source_noun_phrases_lst_without_sw = [word for word in source_noun_phrases_lst if not word in all_stopwords]\n",
    "\n",
    "\n",
    "target = ' '.join(target_noun_phrases_lst_without_sw)\n",
    "source = ' '.join(source_noun_phrases_lst_without_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3b810a",
   "metadata": {},
   "source": [
    "## Load the model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89f4b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "from keras import models\n",
    "model = models.load_model('../model_keras/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa37db3",
   "metadata": {},
   "source": [
    "#### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4029481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "46a9fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kg = [('sky', 'ocean')]\n",
    "# ca = [('sky',)]\n",
    "\n",
    "# kg = [('Book', 'Creative Writing')]\n",
    "# ca = [('Book',)]\n",
    "\n",
    "kg = [(target, source)]\n",
    "ca = [(target,)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4135af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6031bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign unique IDs to words in vocabulary\n",
    "word_to_id = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9cdda880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode triples and concepts with unique IDs\n",
    "encoded_triples = [[word_to_id[word] for word in each] for each in kg]\n",
    "encoded_concepts = [[word_to_id[word] for word in each] for each in ca]\n",
    "# Pad encoded sequences\n",
    "max_length = max(len(seq) for seq in encoded_triples + encoded_concepts)\n",
    "padded_triples = pad_sequences(encoded_triples, maxlen=max_length, padding='post')\n",
    "padded_concepts = pad_sequences(encoded_concepts, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c5370c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([padded_triples, padded_concepts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "32341f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_pred).astype(int).flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
